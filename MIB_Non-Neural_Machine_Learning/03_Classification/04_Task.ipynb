{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "288px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pTFZ0Lzjw9Q"
      },
      "source": [
        "# The dataset\n",
        "\n",
        "We will work with the somewhat misleadingly named \"Adult Data Set\" from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult). The data is in the file \"adult.csv\".\n",
        "\n",
        "**General info**\n",
        "> Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset.\n",
        "\n",
        "\n",
        "**Field info**\n",
        "> age: continuous.\n",
        "\n",
        "> workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
        "\n",
        "> fnlwgt: continuous.\n",
        "\n",
        "> education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters,\n",
        "1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
        "\n",
        "> education-num: continuous.\n",
        "\n",
        ">marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
        "\n",
        ">occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, \n",
        "Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
        "\n",
        ">relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
        "\n",
        "> race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
        "\n",
        "> sex: Female, Male.\n",
        "\n",
        "> capital-gain: continuous.\n",
        "\n",
        "> capital-loss: continuous.\n",
        "\n",
        "> hours-per-week: continuous.\n",
        "\n",
        "> native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbZu8tHKjw9T"
      },
      "source": [
        "# Loading and exploring the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "praKKSPLML3n"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1NTDeOe8KJnXy6OVfBjpiJoZzdjtM5Hvi\" -O adult.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kmyBUwGajw9W"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"adult.csv\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "P0GumRZfjw9q"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrx-TppVML3p"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CSxyBFCljw93"
      },
      "source": [
        "# implement a histogram of the age variable with 30 bins for exploration\n",
        "df..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFOEC6ddML3q"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qfmxlM71jw9_"
      },
      "source": [
        "# implement a histogram of the capital_gain and capital_loss variables with 30 bins for exploration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgpDYnvijw-R"
      },
      "source": [
        "## Task\n",
        "\n",
        "Let us clarify the relationship between the education_num and education colums."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JfY5jkcmjw-T"
      },
      "source": [
        "# Try to find the relationship between the eduction and education_num variables \n",
        "# do a sorted and de-duplicated printout of a subset dataframe with the education and education_num\n",
        "# and observe the relationship between the values.\n",
        "# Is there a systematic mapping?\n",
        "# Take the DataFrame, subset it by columns, look into drop_duplicates and sort_values functions!\n",
        "# Bear in mind that these functions can be chained with . syntax\n",
        "\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoI7YIvxjw-h"
      },
      "source": [
        "Conclusion: the education_num column is a good linear scale encoding of the education columm, so we can get rid of the latter. \n",
        "\n",
        "## Task\n",
        "\n",
        "We can also drop the (for us) useless \"fnlwgt\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eQRLAsS3jw-o"
      },
      "source": [
        "# get rid of the \"fnlwgt\", \"education\" columns, since we will not need them\n",
        "# drop the columns by name\n",
        "\n",
        "...\n",
        "\n",
        "# let's see!\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmH3WUhHjw-5"
      },
      "source": [
        "## Task\n",
        "\n",
        "We can encode the binary category values as binary codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "twR9DO4Vjw-7"
      },
      "source": [
        "# use the replace method of pandas to change the encoding \n",
        "# of male and female in the sex column to 1 for female and 0 for male \n",
        "...\n",
        "\n",
        "# \n",
        "# do the same binary encoding for the income column with >50K and <=50K to 1 and 0\n",
        "# please encode >50K as 1 and <=50K as 0, and ensure that the resulting column consists\n",
        "# exclusively of integers (!)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7NBSF-PDjw_D"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpfCmO5Bjw_N"
      },
      "source": [
        "# Clustering\n",
        "\n",
        "## Task: K-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQgJPXoBjw_O"
      },
      "source": [
        "We try to cluster the data using the age and education_num columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5wXFSIQtjw_R"
      },
      "source": [
        "from sklearn import cluster\n",
        "# initialze a KMeans object with 2 clusters\n",
        "kmeans = ...\n",
        "\n",
        "# put the predictions of the kmeans clustering based on \"age\" and \"education_num\" \n",
        "# (we use these two numerical features for easy 2d visualization)\n",
        "# into a new column of the df; don't do it in separate steps, only one go!\n",
        "df[\"kmeans_pred\"] = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkbn0vnEjw_Y"
      },
      "source": [
        "## Task\n",
        "\n",
        "The result can be visualised, e.g., with a scatter plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "oVEzNQwmjw_a"
      },
      "source": [
        "from matplotlib import pylab # we use this for nice coloring - optional cmap\n",
        "\n",
        "# do a scatter plot for \"age\", \"education_num\", c=\"kmeans_pred\"\n",
        "# replace the ... part, please!\n",
        "df.plot.scatter( ... , cmap=pylab.cm.cool, figsize=(10,8),\n",
        "                alpha=0.3, # show overlap \n",
        "                sharex=False);  # sharex=False is apparently needed because of a bug which causes the xaxis\n",
        "                                # ticks to disappear when the colormap is shown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hycF0jHjw_h"
      },
      "source": [
        "## Task\n",
        "\n",
        "Let's try the same but with standardizing the variables first.\n",
        "Standardizing means putting different variables on the same scale.\n",
        "Now we should not do it \"by hand\", but use the standard scaler of Scikit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9sWrczeAjw_i"
      },
      "source": [
        "\n",
        "# import an appropriate standard scaler class from Scikit\n",
        "...\n",
        "\n",
        "# Instantiate a scaler object\n",
        "...\n",
        "\n",
        "\n",
        "# use the object to standardize the age and education columns of the df \n",
        "# and save the results to a new variable \"standardized\" in only one go!\n",
        "...\n",
        "\n",
        "#fit a kmeans clustering on the new, standardized values, and put the predictions into a new column of the df\n",
        "...\n",
        "\n",
        "#let's see the result on a scatterplot!\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DbVAD-ZML3x"
      },
      "source": [
        "Observe the effect of standardization on the clustering! \n",
        "Let's discuss why!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z76g88rjw_t"
      },
      "source": [
        "A visualisation of the \"real\" class labels in the same space.\n",
        "Observe the same pattern!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KxBmEKbyjw_v"
      },
      "source": [
        "df.plot.scatter(\"age\", \"education_num\", c=\"income\", cmap=pylab.cm.cool, figsize=(10,8),\n",
        "                    alpha=0.3, # show overlap\n",
        "                    sharex=False);   # sharex=False is apparently needed because of a bug which causes the xaxis\n",
        "                                    # ticks to disappear when the colormap is shown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fX50N5yjxAI"
      },
      "source": [
        "## Task\n",
        "\n",
        "It is an interesting question what are the precision etc. scores of this clustering with respect to our original class labels as if it were a classification task. Please print out the metrics!\n",
        "\n",
        "> Note: only do this task if you turned `income` into a binary variable under \"Loading and exploring the data\"!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## to make sure the cluster labels are aligned with the class labels -- you don't have to do anything, just run the code.\n",
        "\n",
        "tmp = df[[\"kmeans_pred\", \"income\", ]].value_counts()\n",
        "tmp = tmp[~tmp.index.get_level_values(1).duplicated(keep=\"first\")]\n",
        "most_common_pairs = tmp.iloc[:2]\n",
        "display(most_common_pairs)\n",
        "## create a most probable kmeans cluster number : category number dictionary\n",
        "c_dict = dict(most_common_pairs.index.tolist())\n",
        "## turn cluster numbers to category numbers\n",
        "df[\"kmeans_pred\"] = df[\"kmeans_pred\"].map(lambda x: c_dict[x])"
      ],
      "metadata": {
        "id": "OYWuRfXg8QtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "40flhFH1jxAL"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# print out the appropriate metrics imported from Scikit\n",
        "print(\"Precision:\", ...)\n",
        "print(\"Recall:\", ...)\n",
        "print(\"F-measure:\", ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC6ry1kkjxBJ"
      },
      "source": [
        "# Classification\n",
        "\n",
        "## Task\n",
        "\n",
        "We standardize all data we will use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Prbd0BkVjxBL"
      },
      "source": [
        "# initiate and use a standard scaler to scale the \"age\", \"education_num\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\" variables\n",
        "scaler = ...\n",
        "standardized = scaler.fit_transform(df[[...]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR20t63hjxBQ"
      },
      "source": [
        "## Task: Classification results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhrWHFzljxBU"
      },
      "source": [
        "And write a general \"classifier runner\" for our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UmezmMT8jxBV"
      },
      "source": [
        "# Define a function that accepts three arguments:\n",
        "# sklearn classifier, x,y \n",
        "# where x and y are the data. The function should \n",
        "# fit the classification, do a prediction and \n",
        "# calculate and return precision, recall and F1.\n",
        "\n",
        "def classifier_metrics(...):\n",
        "    \"\"\"Run classifier on a dataset and return metrics.\n",
        "    \"\"\"\n",
        "    ...\n",
        "    predictions = ...\n",
        "    return (...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qihXG7TDjxBY"
      },
      "source": [
        "Finally, we run the classifiers\n",
        "\n",
        "- K-nearest neighbour,\n",
        "- Logistic regression,\n",
        "- SVM,\n",
        "- Random Forest\n",
        "\n",
        "on our data set and collect the metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "a7fz5NNpjxBa"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifiers = [(KNeighborsClassifier(), \"knn\"),\n",
        "               (LogisticRegression(), \"lr\"),\n",
        "               (LinearSVC(), \"svm\"),\n",
        "               (RandomForestClassifier(), \"rf\")]\n",
        "\n",
        "results_dict = {name: classifier_metrics(classifier, standardized, df[\"income\"]) for \n",
        "                    classifier, name in classifiers}\n",
        "\n",
        "results = pd.DataFrame(results_dict, index=[\"precision\", \"recall\", \"f-measure\"])\n",
        "\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FETU93hujxBq"
      },
      "source": [
        "## Task: Results with one-hot encoded categorical data\n",
        "\n",
        "What happens if we one-hot encode all categorical features and use them as well?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Axi-U45sjxCA"
      },
      "source": [
        "# use Pandas to do a one-hot encoding of the categorical features in the df dataframe!\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WskAvPgbML32"
      },
      "source": [
        "Now define a new dataframe called df_inputs that contains all columns that are the input features for the classification!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YqC9zGYjxCM"
      },
      "source": [
        "df_inputs = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdL9uVOvML33"
      },
      "source": [
        "Finally, we standardize the data set and run the classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ToFAglRgML33"
      },
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "standardized = scaler.fit_transform(df_inputs)\n",
        "\n",
        "results_dict = {name: classifier_metrics(classifier, standardized, df[\"income\"]) for \n",
        "                    classifier, name in classifiers}\n",
        "\n",
        "results = pd.DataFrame(results_dict, index=[\"precision\", \"recall\", \"f-measure\"])\n",
        "\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}