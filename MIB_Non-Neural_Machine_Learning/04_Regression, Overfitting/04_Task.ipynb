{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgnWE4e95b2y"
      },
      "source": [
        "# The dataset\n",
        "\n",
        "<img src=\"https://www.cityofames.org/Home/ShowImage?id=6334&t=635943415687730000\">\n",
        "\n",
        "(Image source: [City of Ames homepage](https://www.cityofames.org/about-ames))\n",
        "\n",
        "We will use the \"Ames Housing\" dataset that describes properties in Ames (Iowa) together with their estimated value.\n",
        "The list and explanation of all features can be found [here](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt), but we will concentrate only on a few columns, namely\n",
        "\n",
        "- Lot Area (Continuous): Lot size in square feet\n",
        "- Gr Liv Area (Continuous): Above grade (ground) living area square feet\n",
        "- Total Bsmt SF (Continuous): Total square feet of basement area\n",
        "- Garage Cars (Discrete): Size of garage in car capacity\n",
        "- Overall Qual (Ordinal): Rates the overall material and finish of the house\n",
        "- Overall Cond (Ordinal): Rates the overall condition of the house\n",
        "- SalePrice (Continuous): Sale price\n",
        "\n",
        "\n",
        "Our task is to predict the sale price from the other variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se4NsFOX5b20"
      },
      "source": [
        "# Task: loading data and normalizing column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2zrRx2z5b21"
      },
      "source": [
        "! wget \"https://drive.google.com/uc?export=download&id=1PZT1MrswHXYuNUiYxRcPcBZe81uVdPM9\" -O AmesHousing.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JrYdctew5b21"
      },
      "source": [
        "import numpy as np\n",
        "random_seed = 111222\n",
        "np.random.seed(random_seed) #This is good practice for reproducibiity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "n6Mu4jF15b22"
      },
      "source": [
        "# Please load the dataset from AmesHousing.csv with Pandas\n",
        "# and look into it\n",
        "\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "A128WI8n5b22"
      },
      "source": [
        "## nothing to do, just check the column names\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nUcv3SLI5b22"
      },
      "source": [
        "# Let's just look into the numeric columns\n",
        "df = df[[\"Lot Area\", \"Gr Liv Area\", \"Total Bsmt SF\", \"Overall Qual\", \"Overall Cond\", \"Garage Cars\", \"SalePrice\"]]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "W0aaigH85b23"
      },
      "source": [
        "## NOTE: THIS CELL IS AN **OPTIONAL** TASK FOR YOU TO PRACTICE DATA PREPARATION\n",
        "## IF YOU WANT TO JUST FOCUS ON REGRESSION, SKIP **THIS CELL**\n",
        "\n",
        "# Please normalize a column name by downcasing (turn into lower case) and replacing spaces with '_'.\n",
        "# Write a function and use the rename dataframe method\n",
        "...\n",
        "\n",
        "# Let's see how nice it is! :-)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run this cell to make sure that later, regression-related cells work for you, \n",
        "## which refer to the lowercase saleprice variable\n",
        "df.rename(columns=str.lower, inplace=True)"
      ],
      "metadata": {
        "id": "DlpsSvqln0Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tYiTzmvk5b24"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QiXy5WoJ5b24"
      },
      "source": [
        "# Please drop rows with \"empty\" values \n",
        "# Remember to use \"inplace\" syntax for dropping\n",
        "# And the fact that you are dropping rows, not columns (although dropping rows is actually the default in pandas)\n",
        "\n",
        "...\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4zG1VJ75b24"
      },
      "source": [
        "# Task: Dividing the data\n",
        "\n",
        "Please ALWAYS observe this pattern by your project, since without this you have no estimate for real performance!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Tf8TH0GW5b25"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# This is THE gold standard, use it at all times!!!!!!\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "# Please use the above imported function to do a train-valid-test split of 80%-10%-10%\n",
        "# So the trick will be to use train_test_split **twice**, choosing the test_size well!\n",
        "# Make sure to set the random_state parameter to the random_seed.\n",
        "# Note that we here just use train_test_split on the data \"as is\", not on separate X and y data\n",
        "# (consequently, train_test_split will return just TWO things, not four).\n",
        "# The assertions below should be satisfied, that means, \n",
        "# the code will not run further if the shapes and names don't fit!\n",
        "\n",
        "\n",
        "...\n",
        "\n",
        "## the three variables below should be the name of the train, validation and test subdatasets!\n",
        "print(df_train.shape)\n",
        "print(df_valid.shape)\n",
        "print(df_test.shape)\n",
        "\n",
        "assert df_train.shape==(2342, 7)\n",
        "assert df_valid.shape==(293, 7)\n",
        "assert df_test.shape==(293, 7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvc8eqYb5b25"
      },
      "source": [
        "# Task: Fitting a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ihGVsGOy5b26"
      },
      "source": [
        "# Please build a pipeline under the variable \"pipe\" that consists of the application of a scaler \n",
        "# and a linear regression model from Scikit, with the named step of \"lr\".\n",
        "# Do the appropriate imports, of course.\n",
        "\n",
        "...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vKWuZM4f5b26"
      },
      "source": [
        "# Please train (fit) the pipe on the df_train data.\n",
        "# Remember, your target variable should be the saleprice.\n",
        "# Don't forget to remove the target variable (saleprice) from the input, \n",
        "# and store the input in the variable train_input.\n",
        "# The training should run on train_input as X and the saleprice column of your dataframe as y.\n",
        "\n",
        "...\n",
        "\n",
        "\n",
        "## nothing to do here, we just display the coefficients:\n",
        "coefs = pipe.named_steps[\"lr\"].coef_\n",
        "coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6XjmqjV55b27"
      },
      "source": [
        "# No task here. :-)\n",
        "# This is just an intermediary step to transform the coefficients into a nice form, paired with their names, and ordered in a descending order.\n",
        "names_and_coefs = [(df.columns[i], coefs[i]) for i, _ in enumerate(coefs)] # This is a list comprehension inside, https://www.pythonforbeginners.com/basics/list-comprehensions-in-python\n",
        "sorted(names_and_coefs, key=lambda x: x[1], reverse=True) #And this is a lambda https://www.w3schools.com/python/python_lambda.asp\n",
        "# These are by no way mandatory elements of Python, but may come handy at times."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YprDRXTl5b27"
      },
      "source": [
        "pipe.named_steps[\"lr\"].intercept_ # nothing to do, we just display the intercept here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ3q30UG5b27"
      },
      "source": [
        "# Task: Predicting with the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LcOuVuEY5b27"
      },
      "source": [
        "#Please predict on the training input first! (train_input)\n",
        "train_lr_prediction = ...\n",
        "\n",
        "# Please import and calculate mean squared eror and mean absolute error metrics for the training!\n",
        "# Use Scikit's metrics\n",
        "mse=...\n",
        "mae=...\n",
        "\n",
        "print(\"Train mean squared error:\", mse)\n",
        "print(\"Train mean abs. error:\", mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Iapdso4o5b28"
      },
      "source": [
        "# Please repeat the procedure and calculate MAE on the validation dataset!\n",
        "\n",
        "...\n",
        "\n",
        "print(\"Valid mean abs. error:\", valid_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularized versions\n",
        "\n",
        "Below we have implemented the regularized versions of the regression.\n",
        "\n",
        "The task here is just to observe their behavior and discuss it.\n"
      ],
      "metadata": {
        "id": "faGWCxFaSs7h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKZ8v-bg5b28"
      },
      "source": [
        "\n",
        "## Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "k5zTWwXE5b29"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "pipe = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"ridge\", Ridge(alpha=1000.))])\n",
        "pipe.fit(train_input, df_train.saleprice)\n",
        "coefs = pipe.named_steps[\"ridge\"].coef_\n",
        "names_and_coefs = [(df.columns[i], coefs[i]) for i, _ in enumerate(coefs)]\n",
        "sorted(names_and_coefs, key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xj4YX_gO5b29"
      },
      "source": [
        "train_ridge_prediction = pipe.predict(train_input)\n",
        "print(\"Train mean squared error:\", mean_squared_error(df_train.saleprice, train_ridge_prediction))\n",
        "print(\"Train mean abs. error:\", mean_absolute_error(df_train.saleprice, train_ridge_prediction))\n",
        "valid_ridge_prediction = pipe.predict(valid_input)             \n",
        "print(\"Valid mean abs. error:\", mean_absolute_error(df_valid.saleprice, valid_ridge_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAVdZ6-o5b2-"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qb4iCd5O5b2-"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "pipe = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"lasso\", Lasso(alpha=3000))])\n",
        "pipe.fit(train_input, df_train.saleprice)\n",
        "coefs = pipe.named_steps[\"lasso\"].coef_\n",
        "names_and_coefs = [(df.columns[i], coefs[i]) for i, _ in enumerate(coefs)]\n",
        "sorted(names_and_coefs, key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6ZV9B9nh5b2-"
      },
      "source": [
        "train_lasso_prediction = pipe.predict(train_input)\n",
        "print(\"Train mean squared error:\", mean_squared_error(df_train.saleprice, train_lasso_prediction))\n",
        "print(\"Train mean abs. error:\", mean_absolute_error(df_train.saleprice, train_lasso_prediction))\n",
        "valid_lasso_prediction = pipe.predict(valid_input)             \n",
        "print(\"Valid mean abs. error:\", mean_absolute_error(df_valid.saleprice, valid_lasso_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhKUbmMh5b2_"
      },
      "source": [
        "# Task: Observe!\n",
        "\n",
        "**Please observe the training of Ridge and LASSO on the same data!**\n",
        "\n",
        "**Can you mention some interesting / specific observations about the training of these methods?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EoiwRJSP5b2_"
      },
      "source": [
        "# Task: Look at residuals\n",
        "\n",
        "(For more sophisticated inspection of residuals you can use [Yellowbricks](http://www.scikit-yb.org/en/latest/index.html), but let's stick to a manual apprach for now.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8urY8dFj5b2_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Please visualize with a scatterplot the residuals of the LASSO prediction\n",
        "# Let's for now take residuals as being the prediction substracted from the real target value\n",
        "# Do the visualization that plots residuals against the y value!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHUDKpn55b2_"
      },
      "source": [
        "**Please observe and share with us the conclusions!**"
      ]
    }
  ]
}