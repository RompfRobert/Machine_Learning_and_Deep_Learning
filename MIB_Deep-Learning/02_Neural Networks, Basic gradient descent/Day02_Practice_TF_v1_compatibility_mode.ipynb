{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wZNxE395xng"
      },
      "source": [
        "\n",
        "# How did Tensorflow 1.x look like?\n",
        "\n",
        "Programs implemented in Tensorflow can be thought of as consisting of two parts:\n",
        "    - Parts for building up a \"computational graph\".\n",
        "    - Parts for the execution of the graph.\n",
        "\n",
        "Computational graphs consist of Tensorflow operations, where _each \"node\" represents a mathematical operation_. \n",
        "\n",
        "The main purpose of this structure is to allow the high speed execution of the said computations as well as _automatic differentiation_ , meaning the automatic computation of derivatives e.g. in case of a neural network and backpropagation. \n",
        "\n",
        "Tensorflow **1.x** was using a _\"define and run\"_ approach, meaning that the  definition and execution phases happen separately, where other frameworks (like Pytorch and Chainer) utilize a _\"define by run\"_ approach. The latter is becoming more and more widespread, so Tensorflow also incorporated [Tensorflow Eager Execution](https://www.tensorflow.org/guide/eager), but since the baseline approach was the \"define and run\", we illustrate Tensorflow usage at first by this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fnAJWjl5xni"
      },
      "source": [
        "## Basic ops\n",
        "\n",
        "In the cell below let us build up a very simple computational graph. All nodes require 0 or more _tensors_ and return _tensors_ themselves. \n",
        "\n",
        "The most basic of these is [tf.constant](https://www.tensorflow.org/api_docs/python/tf/constant), which expects no input, and returns a value stored in it internally.\n",
        "\n",
        "We can define two floating point constants as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:22.224392Z",
          "start_time": "2020-05-07T13:30:20.369586Z"
        },
        "id": "Or2Fy5UO5xnj",
        "outputId": "228e7e4d-bef3-4432-9a39-72e4e19b2200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "#Don't forget to import Tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# This is _NOT_ a good practice, but for presentation purposes\n",
        "# We wish for a clean output, so we suppress TF's warnings\n",
        "import tensorflow.python.util.deprecation as deprecation\n",
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "\n",
        "\n",
        "# For the illustration of TF1 behavior, we switch off eager execution, which is by now on by default \n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# as seen below, all ops have a dtype - very much in numpy style\n",
        "tensor1 = tf.constant(3.0, dtype=tf.float32)\n",
        "tensor2 = tf.constant(4.0) # also tf.float, implicit\n",
        "print(tensor1, tensor2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEQ_ysta5xnl"
      },
      "source": [
        "**Important**\n",
        "\n",
        "Please notice that by executing the above cell we _don't_ get the result of 3.0 and 4.0, but instead the two atypical variables only give back their \"value\" if we evaluate (execute) the computational graph. \n",
        "\n",
        "For this we need a **Session**, that is an \"execution run\". The code below opens a Session on a computational resource, eg. a GPU or a CPU and through the \"run\" method executes the **computational graph** which was statefully stored. (This is important to remember!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:22.783902Z",
          "start_time": "2020-05-07T13:30:22.226819Z"
        },
        "id": "j_rQRh125xnm",
        "outputId": "e415206d-db2f-4de8-f3f6-377c00b645df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.0, 4.0]\n"
          ]
        }
      ],
      "source": [
        "sess =  tf.compat.v1.Session()\n",
        "print(sess.run([tensor1, tensor2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWbLeESu5xnn"
      },
      "source": [
        "Now we get back the results of 3.0 and 4.0.\n",
        "\n",
        "By adding new operation nodes to the graph we can build up a more complex graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:22.792291Z",
          "start_time": "2020-05-07T13:30:22.786056Z"
        },
        "id": "vk-9Wjce5xno",
        "outputId": "f48588dc-40ba-4b4f-e1bf-aad269c76187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor3: Tensor(\"Add:0\", shape=(), dtype=float32)\n",
            "sess.run(tensor3): 7.0\n"
          ]
        }
      ],
      "source": [
        "tensor3 = tf.add(tensor1, tensor2)\n",
        "print(\"tensor3:\", tensor3)\n",
        "print(\"sess.run(tensor3):\", sess.run(tensor3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpdWiE3F5xnp"
      },
      "source": [
        "This is for the time being not an exceptionally interesting graph, since it always gives back the same result. If we would like to use variable inputs in our computation, we need **Placeholders**. The placeholder can be considered as a promise that we will give it a value some time during the execution of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:22.812480Z",
          "start_time": "2020-05-07T13:30:22.795890Z"
        },
        "id": "6aqLVJcP5xnq",
        "outputId": "3b917220-a000-4ccd-e9bc-bc5611e56194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.5\n",
            "[3. 7.]\n"
          ]
        }
      ],
      "source": [
        "a = tf.compat.v1.placeholder(tf.float32)\n",
        "b = tf.compat.v1.placeholder(tf.float32)\n",
        "sum = a + b  # + is a shorthand fo tf.add(), _not_ python + in this case, since it is executed on tf objects\n",
        "print(sess.run(sum, {a: 3, b: 4.5}))\n",
        "print(sess.run(sum, {a: [1, 3], b: [2, 4]}))\n",
        "# Notice, that the execution worked easily for vectors also, so + became a pointwise addition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxozDasm5xns"
      },
      "source": [
        "In machine learning we would typically like to have a model that can handle arbitrary input - as above, and the graph has to be modifiable, \"trainable\", so that by changing the parameters it should give different responses to the same inputs. The trainable parameters are represented by **Variables** in Tensorflow which represent the learned parameters of the model. _Before use, Variables have to be initialized_ to some value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:23.056637Z",
          "start_time": "2020-05-07T13:30:22.816031Z"
        },
        "id": "oHxc5leu5xns",
        "outputId": "42f711d9-585b-4520-8b8c-28c713037cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2.9800003]]\n"
          ]
        }
      ],
      "source": [
        "#Some initial parameters we set up for the \"model\"\n",
        "w = tf.Variable([[.3],[.2],[.5],[.27]], dtype=tf.float32)\n",
        "b = tf.Variable([-.3], dtype=tf.float32)\n",
        "\n",
        "# We define the placeholder that will accept the inputs later on\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=(1,4))\n",
        "\n",
        "# We define a simple transformation akin to a linear model\n",
        "my_transformation = tf.matmul(x,w)+b\n",
        "# Bear in mind, this is proper vector multiplication,\n",
        "# q*r + u would be _pointwise_ multiply, not matrix multiply!\n",
        "\n",
        "# We initialize the variables, that is, a computational graph gets built in the background\n",
        "# and the intialization values we provided above gets put into the Variable instances\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "# We used the previously opened session to execute our init\n",
        "sess.run(init)\n",
        "# And finally we feed in some values to execute our model calculation\n",
        "print(sess.run(my_transformation, {x: [[1., 2., 3., 4.]]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_DtYsTB5xnt"
      },
      "source": [
        "In order to be able to evaluate the model, we create a placeholder for the target value called y, and we write a simple \"loss function\".\n",
        "\n",
        "The loss function measures the distance of the output from the target value. This example is a standard linear regression (same as we have used in Scikit), which uses the square of deltas between prediction and target. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:23.148504Z",
          "start_time": "2020-05-07T13:30:23.066483Z"
        },
        "id": "9eei5WRN5xnt",
        "outputId": "be31fc02-bb5f-4374-85ef-7dda04907929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.048399907\n"
          ]
        }
      ],
      "source": [
        "y = tf.compat.v1.placeholder(tf.float32)\n",
        "squared_deltas = tf.square(my_transformation - y)\n",
        "loss = tf.reduce_sum(squared_deltas)\n",
        "# This is just a funny syntax for sum - albeit potentially by axes...\n",
        "# https://www.tensorflow.org/api_docs/python/tf/reduce_sum\n",
        "\n",
        "\n",
        "print(sess.run(loss, {x: [[1, 2, 3, 4]], y: [3.2]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv_2KW1O5xnu"
      },
      "source": [
        "## Operations vs tensors in TensorFlow\n",
        "\n",
        "> Though this be madness, yet there is method in't\n",
        "> (Polonius in Hamlet)\n",
        "\n",
        "With simplification:\n",
        "\n",
        "- tf.Operation objects:  Nodes in the computational graph -- operating on tensors and resulting in tensors.\n",
        "- tf.Tensor objects: Edges of the computational graph. \"A `Tensor` is a symbolic handle to one of the outputs of an\n",
        "  `Operation`. These represent the values that will flow through the graph. A `tf.Tensor` object represents a partially defined computation that will eventually produce a value.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUzcgVW5xnv"
      },
      "source": [
        "When we build the computational graphs we _jointly_ create operations and tensors (or more precisely pointers, references to them) in one go:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:23.187965Z",
          "start_time": "2020-05-07T13:30:23.164735Z"
        },
        "scrolled": true,
        "id": "pDu-Tc3e5xnv",
        "outputId": "95f117cb-0317-4ae2-93e1-810a3b3ab234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Const type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "Const name: Constantine:0\n",
            "The Operation for the Const: <class 'tensorflow.python.framework.ops.Operation'>\n",
            "The name of the Operation for the Const: Constantine\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.reset_default_graph()\n",
        "# This is VERY good practice, since the default graph is stateful, so noone knows, what derbis is in there...\n",
        "\n",
        "const = tf.constant(1, name=\"Constantine\")\n",
        "print(\"Const type:\", type(const))\n",
        "print(\"Const name:\", const.name)\n",
        "print(\"The Operation for the Const:\", type(const.op))\n",
        "print(\"The name of the Operation for the Const:\", const.op.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRrogM9C5xnx"
      },
      "source": [
        "Please observe, that `name` is an important and _automatically generated_ property of a tensor, that is why we see `Constantine:0` instead of `Constantine` - though we intended to use that. To a quote a Tensorflow developer, this somewhat annoying feature is the result of the fact that:\n",
        "\n",
        "\"...The name of a Tensor is the concatenation of\n",
        "\n",
        "1. the name of the operation that produced it,\n",
        "2. a colon (:), and\n",
        "3. the index of that tensor in the outputs of the operation that produced it.\n",
        "\n",
        "Therefore the tensor named \"foo:2\" is the output of the op named \"foo\" at position 2 (with indices starting from zero).\n",
        "\n",
        "The naming of `tf.Variable` objects is slightly strange. Every `tf.Variable` contains a mutable tensor object that holds the state of the variable (and a few other tensors). A \"Variable\" op (which has the name \"variable_name\" ...) \"produces\" this mutable tensor each time it is run as its 0th output, so the name of the mutable tensor is \"variable_name:0\".\n",
        "\n",
        "Since a `tf.Variable` is mostly indistinguishable from a `tf.Tensor` — in that it can be used in the same places — we took the decision to make variable names resemble tensor names, so the `Variable.name` property returns the name of the mutable tensor.\"\n",
        "\n",
        "[source](https://stackoverflow.com/questions/36150834/how-does-tensorflow-name-tensors)\n",
        "\n",
        "If this is not readily obvious, don't bother, any time you can not fetch a value, remember to add `:0`. ;-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVO9rVJA5xny"
      },
      "source": [
        "## Context management\n",
        "\n",
        "Python has a powerful tool for managing \"external resources\", like open files, or - by the way - open computational sessions.\n",
        "\n",
        "Tensorflow's main design pattern typicaly relies on context management to handle the open session, as well as closing it in the end.\n",
        "\n",
        "### Context managemenat main rule:\n",
        "\n",
        "**As long as a context manager code block is open, a resource is available.**\n",
        "\n",
        "The context manager provides opportunity for exposing the resource to the block with a name.\n",
        "\n",
        "Below an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-07T13:30:23.234043Z",
          "start_time": "2020-05-07T13:30:23.198610Z"
        },
        "id": "iDbwGngL5xny",
        "outputId": "4c8bf4d0-acf1-43bd-eab7-269ae49aa4f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does sess exist? False\n",
            "Is sess open? True\n",
            "Is sess closed? True\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "del sess\n",
        "print(\"Does sess exist?\",'sess' in globals())\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    print(\"Is sess open?\",not sess._closed)\n",
        "    sess.run(init)\n",
        "    \n",
        "print(\"Is sess closed?\", sess._closed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7n2QKTR5xny"
      },
      "source": [
        "Word of warning: Neither `sess.close()`, nor the contex manager trick works when session is not run inside context. This has no practical relavance, but is rather curious..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPvtltms5xnz"
      },
      "source": [
        "# More reading:\n",
        "\n",
        "TensorFlow is changing and evolving extremely rapidly, worth digging into!\n",
        "\n",
        "Read more under: [A Tour of TensorFlow](https://arxiv.org/pdf/1610.01178.pdf) or in theory: [A Computational Model for TensorFlow](http://delivery.acm.org/10.1145/3090000/3088527/pldiws17mapl-maplmainid2.pdf)\n",
        "\n",
        "And follow what hapens at: https://www.tensorflow.org/ecosystem/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}